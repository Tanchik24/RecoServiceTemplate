{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T17:07:37.396936Z",
     "start_time": "2023-12-12T17:07:37.126108Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from lightfm import LightFM\n",
    "from tqdm import tqdm\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "\n",
    "from rectools.models import ImplicitALSWrapperModel, LightFMWrapperModel\n",
    "from rectools.dataset import Dataset\n",
    "from rectools import Columns\n",
    "from rectools.models import PopularModel, RandomModel, ImplicitALSWrapperModel\n",
    "from rectools.metrics import Precision, Recall, MAP, calc_metrics\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from implicit.lmf import LogisticMatrixFactorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('/Users/tanchik/Desktop/Настоящее/учеба/RecSys/RecoServiceTemplate/kion_train/users.csv')\n",
    "items = pd.read_csv('/Users/tanchik/Desktop/Настоящее/учеба/RecSys/RecoServiceTemplate/kion_train/items.csv')\n",
    "interactions = pd.read_csv(\n",
    "    '/Users/tanchik/Desktop/Настоящее/учеба/RecSys/RecoServiceTemplate/kion_train/interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions.drop(columns='total_dur')\n",
    "interactions_df['watched_pct'] = interactions_df['watched_pct'] / 100\n",
    "interactions_df.rename(columns={'user_id': Columns.User, 'item_id': Columns.Item,\n",
    "                                'last_watch_dt': Columns.Datetime, 'watched_pct': Columns.Weight}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df[Columns.Datetime] = pd.to_datetime(interactions_df[Columns.Datetime], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = interactions_df[Columns.Datetime].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (4984443, 4)\n",
      "test: (490980, 4)\n"
     ]
    }
   ],
   "source": [
    "train = interactions_df[interactions_df[Columns.Datetime] < max_date - pd.Timedelta(days=7)].copy()\n",
    "test = interactions_df[interactions_df[Columns.Datetime] >= max_date - pd.Timedelta(days=7)].copy()\n",
    "\n",
    "print(f\"train: {train.shape}\")\n",
    "print(f\"test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_users = set(test[Columns.User]) - set(train[Columns.User])\n",
    "test.drop(test[test[Columns.User].isin(cold_users)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.fillna('Unknown', inplace=True)\n",
    "users = users.loc[users[Columns.User].isin(train[Columns.User])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973171</td>\n",
       "      <td>М</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>М</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>Ж</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>Ж</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1037719</td>\n",
       "      <td>М</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id value feature\n",
       "0   973171     М     sex\n",
       "1   962099     М     sex\n",
       "3   721985     Ж     sex\n",
       "4   704055     Ж     sex\n",
       "5  1037719     М     sex"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_frames = []\n",
    "for feature in [\"sex\", \"age\", \"income\"]:\n",
    "    feature_frame = users.reindex(columns=[Columns.User, feature])\n",
    "    feature_frame.columns = [\"id\", \"value\"]\n",
    "    feature_frame[\"feature\"] = feature\n",
    "    user_features_frames.append(feature_frame)\n",
    "user_features = pd.concat(user_features_frames)\n",
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.loc[items[Columns.Item].isin(train[Columns.Item])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>драмы</td>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>зарубежные</td>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>детективы</td>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>мелодрамы</td>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>зарубежные</td>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       value feature\n",
       "0  10711       драмы   genre\n",
       "0  10711  зарубежные   genre\n",
       "0  10711   детективы   genre\n",
       "0  10711   мелодрамы   genre\n",
       "1   2508  зарубежные   genre"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explode genres to flatten table\n",
    "items[\"genre\"] = items[\"genres\"].str.lower().str.replace(\", \", \",\", regex=False).str.split(\",\")\n",
    "genre_feature = items[[\"item_id\", \"genre\"]].explode(\"genre\")\n",
    "genre_feature.columns = [\"id\", \"value\"]\n",
    "genre_feature[\"feature\"] = \"genre\"\n",
    "genre_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_feature = items.reindex(columns=[Columns.Item, \"content_type\"])\n",
    "content_feature.columns = [\"id\", \"value\"]\n",
    "content_feature[\"feature\"] = \"content_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = pd.concat([genre_feature, content_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name = {\n",
    "    'Precision': Precision,\n",
    "    'Recall': Recall,\n",
    "    'MAP': MAP,\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for metric_name, metric in metrics_name.items():\n",
    "    for k in range(1, 11):\n",
    "        metrics[f'{metric_name}@{k}'] = metric(k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RECOS = 10\n",
    "RANDOM_STATE = 42\n",
    "NUM_THREADS = 6\n",
    "N_FACTORS = (32,)\n",
    "N_EPOCHS = 1  # Lightfm\n",
    "USER_ALPHA = 0  # Lightfm\n",
    "ITEM_ALPHA = 0  # Lightfm\n",
    "LEARNING_RATE = 0.05  # Lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0.0\n",
       "item_id     0.0\n",
       "datetime    0.0\n",
       "weight      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'popular': PopularModel(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightfm_losses = 'bpr'\n",
    "models = {}\n",
    "\n",
    "models[f\"LightFM_bpr_32\"] = LightFMWrapperModel(\n",
    "            LightFM(\n",
    "                no_components=32,\n",
    "                loss=lightfm_losses,\n",
    "                random_state=RANDOM_STATE,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                user_alpha=USER_ALPHA,\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "            ),\n",
    "            epochs=N_EPOCHS,\n",
    "            num_threads=NUM_THREADS,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 266 ms, total: 1.65 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = Dataset.construct(\n",
    "    interactions_df=train,\n",
    "    user_features_df=user_features,\n",
    "    cat_user_features=[\"sex\", \"age\", \"income\"],\n",
    "    item_features_df=item_features,\n",
    "    cat_item_features=[\"genre\", \"content_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_USERS = test[Columns.User].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model popular...\n",
      "{'Precision@1': 0.07330855141970494, 'Recall@1': 0.038149593189863926, 'Precision@2': 0.0692635125043562, 'Recall@2': 0.07101151735469721, 'Precision@3': 0.06622523883016092, 'Recall@3': 0.10040097751049191, 'Precision@4': 0.05938324565625052, 'Recall@4': 0.11887933072414097, 'Precision@5': 0.05273569093413432, 'Recall@5': 0.13047422807981374, 'Precision@6': 0.04737743186356671, 'Recall@6': 0.13935091270991617, 'Precision@7': 0.04243468077086291, 'Recall@7': 0.14504771897356164, 'Precision@8': 0.03885000580826101, 'Recall@8': 0.15111143638232485, 'Precision@9': 0.035987247640278726, 'Recall@9': 0.15713799491725927, 'Precision@10': 0.03370865762790621, 'Recall@10': 0.16334924892186042, 'MAP@1': 0.038149593189863926, 'MAP@2': 0.05525989453907726, 'MAP@3': 0.06573912068795446, 'MAP@4': 0.07095273573862776, 'MAP@5': 0.0736904806226815, 'MAP@6': 0.07547305264521456, 'MAP@7': 0.07645764528290082, 'MAP@8': 0.07739640676688721, 'MAP@9': 0.07820339897519692, 'MAP@10': 0.07895775354074648}\n",
      "CPU times: user 12.8 s, sys: 490 ms, total: 13.3 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Fitting model {model_name}...\")\n",
    "    model_quality = {'model': model_name}\n",
    "\n",
    "    model.fit(dataset)\n",
    "    recos = model.recommend(\n",
    "        users=TEST_USERS,\n",
    "        dataset=dataset,\n",
    "        k=K_RECOS,\n",
    "        filter_viewed=True,\n",
    "    )\n",
    "    metric_values = calc_metrics(metrics, recos, test, train)\n",
    "    print(metric_values)\n",
    "    model_quality.update(metric_values)\n",
    "    results.append(model_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10440, 15297,  9728, 13865,  4151,  3734,  2657,   142,  6809,\n",
       "        9996,  4880,  8636,  4740, 12192, 11237,  1844,  7571, 12995,\n",
       "        4457, 14431, 14741,  7829,  4495,  7417, 14703,  4436,  7102,\n",
       "        7107, 16228, 11863,  7793, 12173,   849,  7626, 13018, 16166,\n",
       "        3784])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recos['item_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNRecommendation:\n",
    "    def __init__(self, model, dataset, M = 48, efc = 100, num_threads = 6, K = 10):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.M = M\n",
    "        self.efc = efc\n",
    "        self.K = K\n",
    "        self.space_name = 'negdotprod'\n",
    "        self.num_threads = num_threads\n",
    "        self.user_embeddings = None\n",
    "        self.item_embeddings = None\n",
    "        self.augmented_factors = None\n",
    "        self.augmented_user_embeddings = None\n",
    "        self.index_time_params = {'M': M, 'indexThreadQty': num_threads, 'efConstruction': efc, 'post': 0}\n",
    "    \n",
    "    def get_vectors(self):\n",
    "        self.user_embeddings, self.item_embeddings = model.get_vectors(dataset)\n",
    "        user_shape, item_shape = self.user_embeddings.shape, self.item_embeddings.shape\n",
    "        print(f'Размер эмбединга для юзеров: {user_shape} \\n Размер эмбединга для айтемо: {item_shape}')\n",
    "        \n",
    "    def augment_inner_product(self):\n",
    "        normed_factors = np.linalg.norm(self.item_embeddings, axis=1)\n",
    "        max_norm = normed_factors.max()\n",
    "\n",
    "        extra_dim = np.sqrt(max_norm ** 2 - normed_factors ** 2).reshape(-1, 1)\n",
    "        self.augmented_item_embeddings = np.append(self.item_embeddings, extra_dim, axis=1)\n",
    "        \n",
    "    def get_augment_user_embeddings(self):\n",
    "        extra_zero = np.zeros((self.user_embeddings.shape[0], 1))\n",
    "        self.augmented_user_embeddings = np.append(self.user_embeddings, extra_zero, axis=1)\n",
    "        \n",
    "    def create_index(self):\n",
    "        self.index = nmslib.init(method='hnsw', space=self.space_name, data_type=nmslib.DataType.DENSE_VECTOR)\n",
    "        self.index.addDataPointBatch(self.augmented_item_embeddings)\n",
    "        start = time.time()\n",
    "        self.index.createIndex(self.index_time_params)\n",
    "        end = time.time()\n",
    "        print('Index-time parameters', self.index_time_params)\n",
    "        print('Indexing time = %f' % (end-start))\n",
    "        \n",
    "    def create_query_params(self):\n",
    "        query_time_params = {'efSearch': self.efc}\n",
    "        print('Setting query-time parameters', query_time_params)\n",
    "        self.index.setQueryTimeParams(query_time_params)\n",
    "        \n",
    "    def fit(self):\n",
    "        self.get_vectors()\n",
    "        self.augment_inner_product()\n",
    "        self.get_augment_user_embeddings()\n",
    "        self.create_index()\n",
    "        self.create_query_params()\n",
    "        \n",
    "    def save_to_file(self, filename):\n",
    "        state = {k: v for k, v in self.__dict__.items() if k != 'index'}\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(state, file)\n",
    "         \n",
    "    def get_recommendation(self, users):\n",
    "        users_intermal_ids = self.dataset.user_id_map.convert_to_internal(users)\n",
    "        query_matrix = self.augmented_user_embeddings[users_intermal_ids, :]\n",
    "        query_qty = query_matrix.shape[0]\n",
    "        start = time.time()\n",
    "        nbrs = self.index.knnQueryBatch(query_matrix, k=self.K, num_threads=self.num_threads)\n",
    "        end = time.time()\n",
    "        print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' % \n",
    "              (end-start, float(end-start)/query_qty, self.num_threads*float(end-start)/query_qty))\n",
    "        results = nbrs[0][0]\n",
    "        \n",
    "        items = dataset.item_id_map.convert_to_external(results)\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер эмбединга для юзеров: (962151, 52) \n",
      " Размер эмбединга для айтемо: (15605, 52)\n",
      "Index-time parameters {'M': 48, 'indexThreadQty': 6, 'efConstruction': 100, 'post': 0}\n",
      "Indexing time = 0.225880\n",
      "Setting query-time parameters {'efSearch': 100}\n"
     ]
    }
   ],
   "source": [
    "ann = ANNRecommendation(model, dataset)\n",
    "ann.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'nmslib.dist.FloatIndex' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mimlicit.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(ann, file)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'nmslib.dist.FloatIndex' object"
     ]
    }
   ],
   "source": [
    "with open('imlicit.pkl', 'wb') as file:\n",
    "    pickle.dump(ann, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN time total=0.005111 (sec), per query=0.002555 (sec), per query adjusted for thread number=0.015333 (sec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10440,  9728, 13865, 15297,  7829, 12995, 12356,  4457,  3734,\n",
       "        7793])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.get_recommendation([1000, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Distance.DOT: 1>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.u2i_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
